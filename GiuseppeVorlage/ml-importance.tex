\usepackage{xargs}

%\DeclareMathOperator*{\argmin}{arg\,min}
%\newcommand{\argmin}{\operatornamewithlimits{arg\,min}}
\newcommand{\argmin}{\mathop{\mathrm{arg\,min}}}

% basic probability + stats
\renewcommand{\P}{\mathds{P}}                                               % P, probability
\newcommand{\E}{\mathds{E}}                                                 % E, expectation
\newcommand{\var}{\mathsf{Var}}                                             % Var, variance
\newcommand{\cov}{\mathsf{Cov}}                                             % Cov, covariance
\newcommand{\corr}{\mathsf{Corr}}                                           % Corr, correlation
\newcommand{\normal}{\mathcal{N}}                                           % N of the normal distribution
\newcommand{\iid}{\overset{i.i.d}{\sim}}                                    % dist with i.i.d superscript
\newcommand{\distas}[1]{\overset{#1}{\sim}}                                 % ... is distributed as ...

% sets
\renewcommand{\S}{S}
\newcommand{\Spi}[1][j]{B_{#1} (\pi)}
\newcommand{\Scpi}[1][j]{A_{#1} (\pi)}
\newcommand{\Sc}{C}
\newcommand{\Sj}{\S \cup \{j\}}
\newcommand{\pairs}[1]{\{ (#1) \}}

\newcommand{\Lswitch}[1][\Xperm_{\S}]{L (\fh (#1, \XC ), Y)}
\newcommand{\Eswitch}{\E (\Lswitch)} %\E_{\Xperm_\S}(GE(\fh(\Xperm_\S, X_{\Sc})))
\newcommand{\Eorig}{\E (L (\fh (X), Y)) } %GE(\fh(X_\S, X_{\Sc}))
											% xi, slack variable (SVM)

% machine learning

%%%%%% ml - data
\newcommand{\Xspace}{\mathcal{X}}                                           % X, input space
\newcommand{\Yspace}{\mathcal{Y}}                                           % Y, output space
\newcommand{\X}{\mathbf{X}}
\newcommand{\nset}{\{1, \ldots, n\}}                                        % set from 1 to n
\newcommand{\pset}{\{1, \ldots, p\}}                                        % set from 1 to p
\newcommand{\gset}{\{1, \ldots, g\}}                                        % set from 1 to g
\newcommand{\Pxy}{\P_{xy}}                                                  % P_xy
% observation (x, y)
\newcommand{\xvec}{(x_1, \ldots, x_p)^\top}                                 % (x1, ..., xp)
\newcommand{\xivec}{(x^{(i)}_1, \ldots, x^{(i)}_p)^\top}                    % (x1^i, ..., xp^i)
\renewcommand{\xi}[1][(i)]{\mathbf{x}^{#1}}                                          % x^i
\newcommand{\xis}[1][(i)]{\mathbf{x}_{\S}^{#1}}                                          % x^i
\newcommand{\zi}[1][(i)]{\mathbf{z}^{#1}}
\newcommand{\zis}[1][(i)]{\mathbf{z}_{\S}^{#1}}                                          % x^i
\newcommand{\zic}[1][(i)]{\mathbf{z}_{\Sc}^{#1}}                                          % x^i
\newcommand{\xic}[1][(i)]{\mathbf{x}_{\Sc}^{#1}}                                          % x^i
\newcommand{\xij}{x_j^{(i)}}
\newcommand{\yi}[1][(i)]{y^{#1}}                                            % y^i
\newcommand{\xyi}{(\xi, \yi)}                                               % (x^i, y^i)
\newcommand{\xy}{(x, y)}                                                    % (x, y)
% data
\newcommand{\D}{\mathcal{D}}                                                % D, data
%\newcommand{\Dset}{\{ (\mathbf{x}^{(1)}, y^{(1)}), \ldots, (\mathbf{x}^{(n)},  y^{(n)})\}}    % {(x1,y1)), ..., (xn,yn)} data
\newcommand{\Dset}[1][n]{\pairs{ \mathbf{x}^{(i)}, y^{(i)} }_{i=1}^{#1}}    % {(x1,y1)), ..., (xn,yn)} data
\newcommand{\xdat}{\{ x^{(1)}, \ldots, x^{(n)}\}}   						            % {x1, ..., xn} data
\newcommand{\Dtrain}{\mathcal{D}_{\text{train}}}                            % D_train, training set
\newcommand{\Dtest}{\mathcal{D}_{\text{test}}}                              % D_test, test set
\newcommand{\xj}{\mathbf{x}_j}                                              % x_j (bold)
\newcommand{\xone}{\mathbf{x}_1}                                              % x_j (bold)
\newcommand{\xp}{\mathbf{x}_p}                                              % x_j (bold)
\newcommand{\xS}{\mathbf{x}_S}                                              % x_S (bold)
\newcommand{\xC}{\mathbf{x}_{\Sc}}                                              % x_S (bold)
\newcommand{\Xperm}{\tilde{X}}
\newcommand{\XC}{X_{\Sc}}
\newcommand{\XS}{X_{\S}}
\newcommand{\xjvec}{(x^{(1)}_j, \ldots, x^{(n)}_j)^\top}                    % (x^1_j, ..., x^p_j)
\newcommand{\ydat}{\mathbf{y}}                                              % y (bold)
\newcommand{\yvec}{(y^{(1)}, \hdots, y^{(n)})^\top}                         % (y1, ..., yn)

%%%%%% ml - model
% prediction function f, theta, yhat
\newcommand{\Hspace}{H}
\newcommand{\fx}{f(x)}                                                      % f(x)
\newcommand{\fxh}{\fh(\mathbf x)}                                                   % fhat(x)
\newcommand{\fxt}{f(x | \theta)}                                            % f(x | theta)
\newcommand{\fxi}{f(\xi)}                                                   % f(x^(i))
\newcommand{\fxih}{\hat{f}(\xi)}                                              % f(x^(i))
\newcommand{\fxit}{f(x^{(i)} | \theta)}                                     % f(x^(i) | theta)
\newcommand{\fh}{\hat{f}}                                                   % f hat
\newcommand{\fhS}{\fh_{\S}}
\newcommand{\fS}{f_{\S}}
\newcommand{\fhSi}{\fhS^{(i)}}
\newcommand{\thetah}{\hat{\theta}}                                          % theta hat
\newcommand{\fhD}{\fh_{\D}}                                                 %
\newcommand{\fhDtrain}{\fh_{\Dtrain}}                                       %

\newcommand{\MR}{PFI}
\newcommand{\hMR}{\widehat{\MR}}
\newcommand{\MRS}[1][\S]{\MR_{#1}}
\newcommand{\hMRS}[1][\S]{\hMR_{#1}}
\newcommand{\hMRSa}[1][\S]{\hMR_{#1, \text{approx}}}
%\newcommand{\w}[1][\S]{v_{#1}(\fh, \Dtest)}
\newcommand{\w}[1][(\S)]{v_{GE}#1}
%\newcommand{\Lii}{\Li[(i)]} % L(\fh(\xi), \yi)
%\newcommandx{\Li}[2][1=(k), 2=(i)]{L^{#2}(\fh, \xis[#1])}

\newcommand{\Lii}{L(\fh(\xi), \yi)}
\newcommandx{\Li}[3][1=(k), 2=(i), 3=(i)]{L(\fh(\xis[#1], \xic[#2]), y^{#3})}

\newcommand{\mfeat}{m_{\textnormal{feat}}}
\newcommand{\mobs}{m_{\textnormal{obs}}}

\newcommand{\hPI}{\widehat{PI}_{\S}} %  \widehat{\MR}_{\S}
\newcommand{\PI}[1][\S]{PI_{#1}}
\newcommand{\ICI}{\hMRS^{(i)}}
\newcommand{\ICIvar}[1][(i)]{\MRS^{#1}}
%\newcommandx{\PFIikS}[3][1=\xi, 2=\mathbf{x}_{\S}^{(k)}, 3=\S]{PFI_{#3} (#1, #2)}
%\newcommand{\PFIikS}[1][(k)]{\widehat{\MR}^{(i)} (\xis[#1])} % was used until 29.3
\newcommandx{\PFIikS}[2][1=(i), 2=(k)]{\Delta L^{#1} (\xis[#2])}
%\newcommand{\PFIikS}{\widehat{\MR}^{(i)} (\xis[(k)])}
\newcommand{\yh}{\hat{y}}                                                   % y hat for prediction of target
\newcommand{\yih}{\hat{y}}                                                  % y hat for prediction of target
% prediction function h
\newcommand{\hx}{h(x)}                                                      % h(x)
\newcommand{\hxt}{h(x | \theta)}                                            % h(x | theta)
\newcommand{\hxi}{h(\xi)}                                                   % h(x^(i))
\newcommand{\hxit}{h(x^{(i)} | \theta)}                                     % h(x^(i) | theta)
\newcommand{\hh}{\hat{h}}                                                   % h hat
\newcommand{\hxh}{\hat{h}(x)}                                               % hhat(x)
% risk
% pdf of x and (x,y)
\newcommand{\post}{\P(y = 1 | x)}                                           % P(y = 1 | x), post. prob for y=1
\newcommand{\postk}{\P(y = k | x)}                                          % P(y = k | y), post. prob for y=k
\newcommand{\pik}{\pi_k}                                                    % pi_k, prior
\newcommand{\pix}{\pi(x)}                                                   % pi(x), P(y = 1 | x)
\newcommand{\pixt}{\pi(x | \theta)}                                          %
\newcommand{\pikx}{\pi_k(x)}                                                % pi_k(x), P(y = k | x)
\newcommand{\pikxt}{\pi_k(x | \theta)}                                       %
\newcommand{\pijx}{\pi_j(x)}                                                % pi_j(x), P(y = j | x)
\newcommand{\pixh}{\hat \pi(x)}                                             % pi(x) hat, P(y = 1 | x) hat
\newcommand{\pikxh}{\hat \pi_k(x)}                                          % pi_k(x) hat, P(y = k | x) hat
\newcommand{\pdf}{p}                                                        % p
\newcommand{\pdfx}{p(x)}                                                    % p(x)
\newcommand{\pdfxy}{p(x,y)}                                                 % p(x, y)
\newcommand{\pdfxyt}{p(x, y | \theta)}                                      % p(x, y | theta)
\newcommand{\pdfxyit}{p(\xi, \yi | \theta)}                                 % p(x^(i), y^(i) | theta)
\newcommand{\pdfxyk}{p(x | y=k)}                                            % p(x | y = k)
\newcommand{\pdfxiyk}{p(\xi | y=k)}                                         % p(x^i | y = k)
\newcommand{\lpdfxyk}{\log \pdfxyk}                                         %
\newcommand{\lpik}{\log \pik}                                               %
\newcommand{\pdfygxt}{p(y |x, \theta)}                                      % p(y | x, theta)
\newcommand{\pdfyigxit}{p(\yi |\xi, \theta)}                                % p(y^i |x^i, theta)
\newcommand{\lpdfygxt}{\log \pdfygxt }                                      %
\newcommand{\lpdfyigxit}{\log \pdfyigxit}                                   %

% residual and margin
\newcommand{\eps}{\epsilon}                                                 % residual, stochastic
\newcommand{\epsi}{\epsilon^{(i)}}                                          % r^i, residual, stochastic
\newcommand{\epsh}{\hat{\epsilon}}                                          % residual, estimated
\newcommand{\epshi}{\hat{\epsilon}^{(i)}}
\newcommand{\yf}{y \fx}                                                     % y f(x), margin
\newcommand{\yfi}{\yi \fxi}                                                 % y^i f(x^i), margin
\newcommand{\Sigmah}{\hat \Sigma}									                      		% estimated covariance matrix
\newcommand{\Sigmahj}{\hat \Sigma_j}									                    	% estimated covariance matrix for the j-th class

% ml - loss, risk, likelihood
\newcommand{\Lxy}{L(y, f(x))}                                               % L(y, f(x))
\newcommand{\Lxyi}{L(\yi, \fxi)}                                            % L(y^i, f(x^i))
\newcommand{\Lxyt}{L(y, \fxt)}                                              % L(y, f(x | theta))
\newcommand{\Lxyit}{L(\yi, \fxit)}                                          % L(y^i, f(x^i | theta)
\newcommand{\risk}{\mathcal{R}}                                             % R
\newcommand{\riskf}{\risk(f)}                                               % R(f)
\newcommand{\riske}{\mathcal{R}_{\text{emp}}}                               % R_emp
\newcommand{\riskef}{\riske(f)}                                             % R_emp(f)
\newcommand{\risket}{\mathcal{R}_{\text{emp}}(\theta)}                      % R_emp(theta)
\newcommand{\riskr}{\mathcal{R}_{\text{reg}}}                               % R_reg
\newcommand{\riskrt}{\mathcal{R}_{\text{reg}}(\theta)}                      % R_reg(theta)
\newcommand{\riskrf}{\riskr(f)}                                             % R_reg(f)
\newcommand{\LL}{\mathcal{L}}                                               % L, likelihood
\newcommand{\LLt}{\mathcal{L}(\theta)}                                      % L(theta), likelihood
\renewcommand{\ll}{\ell}                                                    % l, log-likelihood
\newcommand{\llt}{\ell(\theta)}                                             % l(theta), log-likelihood
\newcommand{\LS}{\mathfrak{L}}                                              % ????????????
\newcommand{\TS}{\mathfrak{T}}                                              % ??????????????
\newcommand{\errtrain}{\text{err}_{\text{train}}}                           % training error
\newcommand{\errtest}{\text{err}_{\text{test}}}                             % training error
\newcommand{\errexp}{\overline{\text{err}_{\text{test}}}}                   % training error

% resampling
\newcommand{\GE}[1]{GE(\fh_{#1})}                                           % Generalization error GE
\newcommand{\GEh}[1]{\widehat{GE}_{#1}}                                     % Estimated train error
\newcommand{\GED}{\GE{\D}}                                                  % Generalization error GE
\newcommand{\EGEn}{EGE_n}                                                  % Generalization error GE
\newcommand{\EDn}{\E_{|\D| = n}}                                                  % Generalization error GE
